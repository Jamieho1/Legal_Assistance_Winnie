import spacy
import re
from langdetect import detect

# Define the regular expression for embedded language fragments
embedded_lang_regex = r"\[([a-zA-Z]+)\]"

# Define the named entity recognition function
def recognize_entities(sentence):
    from_lang = detect(sentence)
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(sentence)

    placeholders = {}
    ne_count = 0
    for ent in doc.ents:
        ne_count += 1
        placeholders[ent.text] = f"[NE{ne_count}]"

    for key, value in placeholders.items():
        sentence = sentence.replace(key, value)

    match_iter = re.finditer(embedded_lang_regex, sentence)
    embedded_count = 0
    for match in match_iter:
        embedded_count += 1
        embedded_lang = match.group(1)
        placeholder = f"[EMB_LANG{embedded_count}]"
        placeholders[placeholder] = embedded_lang
        sentence = sentence[:match.start()] + placeholder + sentence[match.end():]

    return sentence, placeholders

# Testing
african_sentence = "Entonga buriijo zikurira omu mbeera y'obwire erikutagata"
ner_sentence, placeholders = recognize_entities(african_sentence)
print(ner_sentence)
print(placeholders)
